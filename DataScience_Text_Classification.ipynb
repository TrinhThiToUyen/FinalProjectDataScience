{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bản sao của Bản sao của ModelAnalysSecmentVietnamese.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TrinhThiToUyen/FinalProjectDataScience/blob/master/DataScience_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30xrEXyIbc9J",
        "colab_type": "code",
        "outputId": "03ed5d3b-c3fa-426d-f998-2f19d20fa194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# Import libraries\n",
        "\n",
        "import pandas as pd\n",
        "import json, codecs, os, csv\n",
        "from time import time\n",
        "import re\n",
        "from lxml.etree import tostring\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "!pip install pyvi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pyvi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/73/89be26d66c71f3bcca1de13bb73a9d622fabe282b55e518d68e86081d4e6/pyvi-0.0.9.7-py2.py3-none-any.whl (8.7MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 3.4MB/s \n",
            "\u001b[?25hCollecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.22.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.28.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/86/cfcd71edca9d25d3d331209a20f6314b6f3f134c29478f90559cee9ce091/python_crfsuite-0.9.6-cp36-cp36m-manylinux1_x86_64.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 23.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (0.14.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.6 pyvi-0.0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIcFoTmg6oEi",
        "colab_type": "code",
        "outputId": "5fba7a10-7e31-4165-e858-53e0472011bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzW981bHbhJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/DataSicence/data_clean.csv\",sep ='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsZRh0jxqgG0",
        "colab_type": "code",
        "outputId": "3314c326-b7cb-44ac-e681-1284330a13c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df['Full_Content'] = df['Title'] +'. '+ df['Content']\n",
        "df_reduce = df.sample(5000)\n",
        "df_reduce.Topic.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pháp luật    1134\n",
              "Thế giới     1098\n",
              "Thời sự      1013\n",
              "Giáo dục      946\n",
              "Khoa học      809\n",
              "Name: Topic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9DAwLEycp43",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "b797de71-cffc-4d56-b6b3-e0e29cd8c209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "#@title \n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "input_gensim = []\n",
        "contents = df['Full_Content'].tolist()\n",
        "for content in contents:\n",
        "    input_gensim.append(ViTokenizer.tokenize(content))\n",
        "    \n",
        "model = Word2Vec(input_gensim, size=128, window=5, min_count=0, workers=4, sg=1)\n",
        "model.wv.save(\"/content/drive/My Drive/DataSicence/word2vec.model\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-140f63c544f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Full_Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minput_gensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mViTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_gensim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ViTokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6ecWPxXcvtn",
        "colab_type": "code",
        "outputId": "f361e4f5-7095-4a3e-82a7-e717d124b894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import gensim.models.keyedvectors as word2vec\n",
        "from pyvi import ViTokenizer\n",
        "model_embedding = word2vec.KeyedVectors.load('/content/drive/My Drive/DataSicence/word2vec.model')\n",
        "word_labels = []\n",
        "max_seq = 2560\n",
        "embedding_size = 128\n",
        "\n",
        "for word in model_embedding.vocab.keys():\n",
        "    word_labels.append(word)\n",
        "    \n",
        "def comment_embedding(comment):\n",
        "    matrix = np.zeros((max_seq, embedding_size))\n",
        "    words = ViTokenizer.tokenize(comment)\n",
        "    lencmt = len(words)\n",
        "\n",
        "    for i in range(max_seq):\n",
        "        indexword = i % lencmt\n",
        "        if (max_seq - i < lencmt):\n",
        "            break\n",
        "        if(words[indexword] in word_labels):\n",
        "            matrix[i] = model_embedding[words[indexword]]\n",
        "    matrix = np.array(matrix)\n",
        "    return matrix"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vItIOAbFc4-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_data = []\n",
        "label_data = []\n",
        "train_data_raw = df_reduce['Full_Content'].to_numpy()\n",
        "label_data_raw = df_reduce['Topic'].to_numpy()\n",
        "\n",
        "for x in train_data_raw:\n",
        "    train_data.append(comment_embedding(x))\n",
        "train_data = np.array(train_data)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR4mBjGY1zy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for y in label_data_raw:\n",
        "    label_ = np.zeros(5)\n",
        "    if y == \"Pháp luật\":\n",
        "      label_[0] = 1\n",
        "    elif y == \"Thế giới\":\n",
        "      label_[1] = 1\n",
        "    elif y == \"Thời sự\":\n",
        "      label_[2] = 1\n",
        "    elif y == \"Giáo dục\":\n",
        "      label_[3] = 1\n",
        "    elif y == \"Khoa học\":\n",
        "      label_[4] = 1\n",
        "    label_data.append(label_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIBgIbg8c8LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_length = 2560\n",
        "embedding_size = 128\n",
        "num_classes = 5\n",
        "filter_sizes = 3\n",
        "num_filters = 150\n",
        "epochs = 50\n",
        "batch_size = 30\n",
        "learning_rate = 0.01\n",
        "dropout_rate = 0.5\n",
        "x_train = train_data.reshape(train_data.shape[0], sequence_length, embedding_size, 1).astype('float32')\n",
        "y_train = np.array(label_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WgVcu6u8Rnr",
        "colab_type": "code",
        "outputId": "24381532-7ce9-4ef2-dc6e-f3240c54e6b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Convolution2D(num_filters, (filter_sizes, embedding_size),\n",
        "                        padding='valid',\n",
        "                        input_shape=(sequence_length, embedding_size, 1), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(18, 1)))\n",
        "model.add(layers.Dropout(dropout_rate))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "# Train model\n",
        "adam = tf.train.AdamOptimizer()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 2558, 1, 150)      57750     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 142, 1, 150)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 142, 1, 150)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 21300)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               2726528   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 2,784,923\n",
            "Trainable params: 2,784,923\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT_YDppp-SO1",
        "colab_type": "code",
        "outputId": "4a8547cb-23de-4f41-9bfd-57b986b30b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train = y_train.astype('float32')\n",
        "y_train.dtype"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASvCsOKFc-VX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "acf39fce-ecb7-4ebc-898b-dcfff44aa5f4"
      },
      "source": [
        "model.fit(x = x_train[:4000], y = y_train[:4000], batch_size = batch_size, verbose=1, epochs=epochs, validation_data=(x_train[4000:5000], y_train[4000:5000]))\n",
        "\n",
        "model.save('/content/drive/My Drive/DataSicence/models.h5')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 4000 samples, validate on 1000 samples\n",
            "Epoch 1/50\n",
            "4000/4000 [==============================] - 17s 4ms/sample - loss: 0.4338 - acc: 0.8127 - val_loss: 0.3721 - val_acc: 0.8372\n",
            "Epoch 2/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.3196 - acc: 0.8630 - val_loss: 0.3270 - val_acc: 0.8612\n",
            "Epoch 3/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.2440 - acc: 0.9018 - val_loss: 0.3324 - val_acc: 0.8712\n",
            "Epoch 4/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.2071 - acc: 0.9169 - val_loss: 0.3247 - val_acc: 0.8676\n",
            "Epoch 5/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1862 - acc: 0.9240 - val_loss: 0.3353 - val_acc: 0.8684\n",
            "Epoch 6/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1733 - acc: 0.9304 - val_loss: 0.3356 - val_acc: 0.8718\n",
            "Epoch 7/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1655 - acc: 0.9335 - val_loss: 0.3619 - val_acc: 0.8698\n",
            "Epoch 8/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1546 - acc: 0.9383 - val_loss: 0.3835 - val_acc: 0.8654\n",
            "Epoch 9/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1510 - acc: 0.9392 - val_loss: 0.3614 - val_acc: 0.8762\n",
            "Epoch 10/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1497 - acc: 0.9398 - val_loss: 0.3682 - val_acc: 0.8712\n",
            "Epoch 11/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1457 - acc: 0.9420 - val_loss: 0.3764 - val_acc: 0.8726\n",
            "Epoch 12/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1425 - acc: 0.9429 - val_loss: 0.3888 - val_acc: 0.8732\n",
            "Epoch 13/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1434 - acc: 0.9421 - val_loss: 0.4267 - val_acc: 0.8644\n",
            "Epoch 14/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1435 - acc: 0.9428 - val_loss: 0.3994 - val_acc: 0.8680\n",
            "Epoch 15/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1379 - acc: 0.9450 - val_loss: 0.4566 - val_acc: 0.8638\n",
            "Epoch 16/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1397 - acc: 0.9441 - val_loss: 0.4000 - val_acc: 0.8718\n",
            "Epoch 17/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1333 - acc: 0.9464 - val_loss: 0.4439 - val_acc: 0.8736\n",
            "Epoch 18/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1350 - acc: 0.9453 - val_loss: 0.4064 - val_acc: 0.8728\n",
            "Epoch 19/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1353 - acc: 0.9449 - val_loss: 0.4488 - val_acc: 0.8686\n",
            "Epoch 20/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1361 - acc: 0.9455 - val_loss: 0.4301 - val_acc: 0.8682\n",
            "Epoch 21/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1312 - acc: 0.9470 - val_loss: 0.4289 - val_acc: 0.8736\n",
            "Epoch 22/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1349 - acc: 0.9455 - val_loss: 0.4378 - val_acc: 0.8688\n",
            "Epoch 23/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1325 - acc: 0.9470 - val_loss: 0.4529 - val_acc: 0.8734\n",
            "Epoch 24/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1343 - acc: 0.9458 - val_loss: 0.4403 - val_acc: 0.8718\n",
            "Epoch 25/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1278 - acc: 0.9482 - val_loss: 0.4449 - val_acc: 0.8724\n",
            "Epoch 26/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1294 - acc: 0.9477 - val_loss: 0.5526 - val_acc: 0.8596\n",
            "Epoch 27/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1286 - acc: 0.9478 - val_loss: 0.4504 - val_acc: 0.8680\n",
            "Epoch 28/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1289 - acc: 0.9481 - val_loss: 0.4532 - val_acc: 0.8724\n",
            "Epoch 29/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1299 - acc: 0.9472 - val_loss: 0.4380 - val_acc: 0.8708\n",
            "Epoch 30/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1310 - acc: 0.9470 - val_loss: 0.4735 - val_acc: 0.8668\n",
            "Epoch 31/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1314 - acc: 0.9461 - val_loss: 0.4402 - val_acc: 0.8750\n",
            "Epoch 32/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1293 - acc: 0.9480 - val_loss: 0.4929 - val_acc: 0.8672\n",
            "Epoch 33/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1281 - acc: 0.9482 - val_loss: 0.4580 - val_acc: 0.8726\n",
            "Epoch 34/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1261 - acc: 0.9487 - val_loss: 0.5026 - val_acc: 0.8674\n",
            "Epoch 35/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1264 - acc: 0.9485 - val_loss: 0.4539 - val_acc: 0.8734\n",
            "Epoch 36/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1284 - acc: 0.9482 - val_loss: 0.4902 - val_acc: 0.8660\n",
            "Epoch 37/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1261 - acc: 0.9486 - val_loss: 0.4579 - val_acc: 0.8726\n",
            "Epoch 38/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1269 - acc: 0.9484 - val_loss: 0.5089 - val_acc: 0.8624\n",
            "Epoch 39/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1318 - acc: 0.9477 - val_loss: 0.4791 - val_acc: 0.8698\n",
            "Epoch 40/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1267 - acc: 0.9488 - val_loss: 0.4476 - val_acc: 0.8710\n",
            "Epoch 41/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1264 - acc: 0.9485 - val_loss: 0.4594 - val_acc: 0.8754\n",
            "Epoch 42/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1251 - acc: 0.9495 - val_loss: 0.5223 - val_acc: 0.8650\n",
            "Epoch 43/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1278 - acc: 0.9485 - val_loss: 0.4798 - val_acc: 0.8706\n",
            "Epoch 44/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1255 - acc: 0.9489 - val_loss: 0.5047 - val_acc: 0.8702\n",
            "Epoch 45/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1258 - acc: 0.9482 - val_loss: 0.6071 - val_acc: 0.8626\n",
            "Epoch 46/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1279 - acc: 0.9482 - val_loss: 0.4882 - val_acc: 0.8730\n",
            "Epoch 47/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1253 - acc: 0.9496 - val_loss: 0.5223 - val_acc: 0.8722\n",
            "Epoch 48/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1254 - acc: 0.9487 - val_loss: 0.5113 - val_acc: 0.8708\n",
            "Epoch 49/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1243 - acc: 0.9496 - val_loss: 0.5404 - val_acc: 0.8688\n",
            "Epoch 50/50\n",
            "4000/4000 [==============================] - 16s 4ms/sample - loss: 0.1238 - acc: 0.9495 - val_loss: 0.5043 - val_acc: 0.8716\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEHQWywd8WH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dicTopic = {0:\"Pháp luật\",\n",
        "       1:\"Thế giới\",\n",
        "       2: \"Thời sự\",\n",
        "       3:\"Giáo dục\",\n",
        "       4:\"Khoa học\"}\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5oYFs5K9ZTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text1 = 'Bé sơ sinh bị rắn cắn tử vong HÀ TĨNH Bé Thái Hữu Tâm, 22 ngày tuổi, ở xã Thọ Điền, huyện Vũ Quang, đang nằm ngủ cạnh mẹ thì bị rắn cạp nia bò lên giường cắn tử vong, sáng 8/1. Lúc 5h sáng, chị Đinh Thị Huyền Trang (mẹ bé Tâm) nghe tiếng con trai khóc liền vùng dậy, phát hiện con rắn màu đen trắng đang bò trên giường nên hô hoán chồng vào dùng gậy đánh chết, đồng thời đưa con trai tới nhà thầy lang trong huyện để cứu chữa. Ông Nguyễn Đăng Nhàn, Chủ tịch UBND xã Thọ Điền, cho biết khi tới nhà thầy lang, người bé Tâm đã cứng, được cho uống thuốc song không qua khỏi. Cán bộ Trạm y tế xã kiểm tra vết thương, xác định bé trai tử vong do bị rắn cạp nia dài hơn một mét cắn trúng tay phải, Vợ chồng chị Trang có ba người con, bé Tâm là con trai út, mới sinh được 22 ngày. Gia đình mới xây nhà, phòng ngủ rất kín đáo, xung quanh khuôn viên có một vài cây bụi, song không quá rậm rạp. Chủ tịch UBND xã Thọ Điền cho hay, vài năm trước, xã cũng có một người đang nằm ngủ bị rắn độc bò vào giường cắn bị thương.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrsDfnwYgXzn",
        "colab_type": "code",
        "outputId": "ae83f483-4284-4f95-a5e7-14efe4371ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#text = 'Lừa bán đất ven sông Hàn. ĐÀ NẴNGVũ Xuân Ngữ (30 tuổi) lừa 3 người với số tiền hơn 7,1 tỷ đồng bằng việc bán đất \"ma\" ven sông Hàn.Ngày 8/1, công an Đà Nẵng đã khởi tố, bắt Ngữ về hành vi lừa đảo chiếm đoạt tài sản. '+'Theo điều tra, Ngữ bịa chuyện có nhiều lô đất ven sông Hàn (đoạn thuộc đường Như Nguyệt, phường Thuận Phước, quận Hải Châu), nhờ người quen làm môi giới.'+'Tháng 3/2018, Ngữ thỏa thuận bán 4 lô đất cho chị Cúc (28 tuổi, trú TP HCM),  thoả thuận bán 4 lô đất với giá mỗi lô 800 triệu đồng cho diện tích 100 m2, rẻ hơn nhiều lần giá thị trường. Ngữ ba lần nhận tiền đặt cọc, tổng cộng 1,5 tỷ đồng.'+'Ngữ sau đó chở chị Cúc đến xem đất, hẹn ngày tách thửa sẽ hoàn tất thủ tục mua bán. Đến tháng 2/2019, Ngữ vẫn không làm được sổ đỏ nhưng tiếp tục yêu cầu chị Cúc chuyển thêm hơn 300 triệu đồng. Biết bị lừa, nạn nhân tố cáo đến công an.'+'Ngữ khai đã lừa bán đất cho hai người khác bằng thủ đoạn tương tự, chiếm đoạt 5,3 tỷ đồng. '\n",
        "maxtrix_embedding = np.expand_dims(comment_embedding(text1), axis=0)\n",
        "maxtrix_embedding = np.expand_dims(maxtrix_embedding, axis=3)\n",
        "\n",
        "result = model.predict(maxtrix_embedding)\n",
        "result = np.argmax(result)\n",
        "print(\"Label predict: \", dicTopic[result])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label predict:  Thời sự\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miYAQrwqDyqi",
        "colab_type": "code",
        "outputId": "435bce60-3032-4dba-8588-cffeba6c64c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP1INxpaD5Kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = []\n",
        "label_test_data = []\n",
        "train_data_raw = df['Full_Content'][20000:22000].to_numpy()\n",
        "label_data_raw = df['Topic'][20000:22000].to_numpy()\n",
        "\n",
        "for x in train_data_raw:\n",
        "    test_data.append(comment_embedding(x))\n",
        "test_data = np.array(test_data)\n",
        "for y in label_data_raw:\n",
        "    label_ = np.zeros(5)\n",
        "    if y == \"Pháp luật\":\n",
        "      label_[0] = 1\n",
        "    elif y == \"Thế giới\":\n",
        "      label_[1] = 1\n",
        "    elif y == \"Thời sự\":\n",
        "      label_[2] = 1\n",
        "    elif y == \"Giáo dục\":\n",
        "      label_[3] = 1\n",
        "    elif y == \"Khoa học\":\n",
        "      label_[4] = 1\n",
        "    label_test_data.append(label_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kchJUu5Z2E6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b280470c-d453-42b3-895c-f05b2022a8b3"
      },
      "source": [
        "x_test = test_data.reshape(test_data.shape[0], sequence_length, embedding_size, 1).astype('float32')\n",
        "y_test = np.array(label_test_data)\n",
        "score=model.evaluate(x_test, y_test, verbose=2)\n",
        "print(score)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 - 2s - loss: 0.5173 - acc: 0.8666\n",
            "[0.5172941989898682, 0.8666]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5tbKSUwaTTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}